\section{Scheduling}

\paragraph{Motivation}
\begin{itemize}
  \item \( K \) jobs ready to run, \( K > N \geq 1 \) CPUs available
  \item \textbf{Scheduling Problem}:
  \begin{itemize}
    \item Which jobs should kernel assign to which CPUs?
    \item When should it make decision?
  \end{itemize}
\end{itemize}

\paragraph{Dispatcher}
\begin{itemize}
  \item \textbf{Dispatcher}: performs actual process switch
  \begin{itemize}
    \item mechanism
    \item save/restore process context
    \item switch to user mode
  \end{itemize}
  \item \textbf{Scheduler}: selects next process to run based on \emph{policy}
\end{itemize}

\paragraph{Voluntary Yielding vs. Preemption}
\begin{itemize}
  \item kernel responsible for CPU switch
  \item kernel doesn't always run \( \to \) can only dispatch different process when invoked
  \item \textbf{cooperative multitasking}: running process performs \emph{yield} syscall
  \begin{itemize}
    \item[$ \to $] kernel switches process 
  \end{itemize}
  \item \textbf{preemptive scheduling}:
  \begin{itemize}
    \item kernel invoked in certain time intervals
    \item kernel makes scheduling decisions after every time-slice
  \end{itemize}
\end{itemize}
\begin{figure}[H]\centering\label{ProcessSwitching}\includegraphics[width=0.33\textwidth]{ProcessSwitching}\end{figure}

\paragraph{Scheduling --- Process States}
\begin{itemize}
  \item \textbf{new}: process was created but did not run yet
  \item \textbf{running}: instructions are currently being executed
  \item \textbf{waiting}: process is waiting for some event
  \item \textbf{ready}: process is waiting to by assigned a processor
  \item \textbf{terminated}: process has finished execution
\end{itemize}

\paragraph{Scheduling --- long-term vs. short-term}
\begin{itemize}
  \item \textbf{Short-term scheduler} (CPU Scheduler, focused on in this lecture):
  \begin{itemize}
    \item selects process to run next, allocates CPU
    \item invoked frequently (ms) \( \leadsto \) must be fast
  \end{itemize}
  \item \textbf{Long-term scheduler} (job scheduler):
  \begin{itemize}
    \item selects process to be brought into ready queue
    \item invoked very infrequently (s, m) \( \leadsto \) can be slow
    \item controls degree of \emph{multiprogramming}
  \end{itemize}
\end{itemize}

\paragraph{Scheduling queues}
\begin{itemize}
  \item \textbf{job queue}: set of all processes in system
  \item \textbf{ready queue}: process in main memory, ready or waiting
  \item \textbf{device queue}: processes waiting for I/O device
\end{itemize}

\paragraph{Scheduling Policies --- Categories}
\begin{itemize}
  \item \textbf{batch scheduling}:
  \begin{itemize}
    \item still widespread in business (payroll, inventory,\dots)
    \item no users waiting for quick response
    \item non-preemptive algorithms acceptable \( \to \) less switches \( \to \) less overhead
  \end{itemize}
  \item \textbf{interactive scheduling}:
  \begin{itemize}
    \item need to optimize for response time
    \item preemption essential to keep processes from hogging CPU
  \end{itemize}
  \item \textbf{real-time scheduling}:
  \begin{itemize}
    \item guarantee job completion within time constraints
    \item need to be able to plan when which process runs + how long
    \item preemption not always needed
  \end{itemize}
\end{itemize}

\paragraph{Scheduling Policies --- Goals}
\begin{itemize}
  \item \textbf{General}:
  \begin{itemize}
    \item \emph{fairness}: give each process fair share of CPU
    \item \emph{balance}: keep all parts of system busy
  \end{itemize}
  \item \textbf{batch scheduling}:
  \begin{itemize}
    \item \emph{throughput}: number of processes that complete per time unit
    \item \emph{turnaround time}: time from job submission to job completion
    \item \emph{CPU utilization}: keep CPU as busy as possible
  \end{itemize}
  \item \textbf{interactive scheduling}:
  \begin{itemize}
    \item \emph{waiting time}: reduce time a process waits in waiting queue
    \item \emph{response time}: time from request to first response
  \end{itemize}
  \item \textbf{real-time scheduling}:
  \begin{itemize}
    \item \emph{meeting deadlines}: finishing jobs in time
    \item \emph{predictability}: minimize jitter
  \end{itemize}
\end{itemize}

\paragraph{Scheduling Policies --- first come first served}
\begin{itemize}
  \item intuitively clear
  \item \textbf{Example}: 3 processes arrive at time 0 in the order \( P_1, P_2, P_3 \)
    \begin{center}
      \begin{tabular}{|c|c|c|}
        \textbf{Process} & \textbf{Burst time} & \textbf{Turnaround time} \\
        \hline
        \( P_1 \) & 24 & 24 \\
        \( P_2 \) & 3 & 27 \\
        \( P_3 \) & 3 & 30
      \end{tabular}
    \end{center}
  \item \( \leadsto \) average turnaround time 27 \( \to \) \emph{can we do better?}
  \item \textbf{Conclusion}: if processes would arrive in order \( P_2 \), \( P_3 \), \( P_1 \), average turnaround time would be 13 \\*
    \( \leadsto \) \emph{good scheduling can reduce turnaround time}
\end{itemize}

\paragraph{Scheduling Policies --- shortest job first}
\begin{itemize}
  \item \textbf{Benefits}: optimal average turnaround/waiting/response time
  \item \textbf{Challenge}: cannot know job lengths in advance
  \item \textbf{Solution}: predict length of next CPU burst for each process \\*
    \( \leadsto \) schedule process with shortest burst next
  \item \textbf{Burst Estimation}: \emph{exponential averaging} \\*
    - \( \tau_{n+1} = \alpha t_n + (1-\alpha)\tau_n \) \\* \phantom{-} (\( t_n \): actual length of \( n \)-th CPU burst, \( \tau_{n+1} \): predicted length of next CPU burst, \( 0 \leq \alpha \leq 1 \))
\end{itemize}

\paragraph{Process Behavior --- CPU bursts}
\begin{itemize}
  \item CPU bursts exists because processes wait for I/O
  \item \textbf{CPU-bound processes}: spends more time doing computations \\*
    \( \leadsto \) few very long CPU bursts
  \item \textbf{I/O-bound processes}: spends more time doing I/O \\*
    \( \leadsto \) many short CPU bursts
\end{itemize}

\paragraph{Scheduling Policies --- preemptive shortest-job-first}
\begin{itemize}
  \item SJF optimizes waiting/response time \\*
    \( \leadsto \) what about throughput?
  \item \textbf{Problem}: CPU-bound jobs hold CPU until exit or I/O \( \to \) \emph{poor I/O utilization}
  \item \textbf{Idea}: SJF, but preempt periodically to make new scheduling decision
  \begin{itemize}
    \item each time slice: schedule job with shortest remaining time next
    \item alternatively: schedule job with shortest next CPU burst
  \end{itemize}
\end{itemize}

\paragraph{Scheduling Policies --- round robin}
\begin{itemize}
  \item \textbf{Problem}: batch schedulers suffer from starvation and don't provide fairness
  \item \textbf{Idea}: each process runs for small CPU time unit
  \begin{itemize}
    \item \emph{time quantum}/\emph{time slice} length: usually 10-100ms
    \item preempt processes that have not blocked by end of time slice
    \item append current thread to end of run queue, run next thread
  \end{itemize}
  \item \textbf{Caution}: time slice length needs to balance interactivity and overhead!
  \begin{itemize}
    \item[$ \to $] if time slice length in the area of dispatch time, 50\% of CPU time wasted for process switching
  \end{itemize}
\end{itemize}

\paragraph{Scheduling Policies --- virtual round robin}
\begin{itemize}
  \item \textbf{Problem}: RR is unfair for I/O-bound jobs: they block before using up time quantum
  \item \textbf{Idea}: put jobs that didn't use up their quantum in additional queue
  \begin{itemize}
    \item store share of unused time-slice
    \item give those jobs additional queue priority
    \item put them back into normal queue afterwards
  \end{itemize}
\end{itemize}

\paragraph{Scheduling Policies --- (strict) priority scheduling}
\begin{itemize}
  \item \textbf{Problem}: not all jobs are equally important \\*
    \( \leadsto \) different priorities (e.g., 4)
  \item \textbf{Solution}: associate priority number with each process
  \begin{itemize}
    \item RR for each priority
    \item \emph{aging}: old low priority processes get executed before new higher priority processes
  \end{itemize}
\end{itemize}

\paragraph{Scheduling Policies --- multi-level feedback queue}
\begin{itemize}
  \item \textbf{Problem}: context switching expensive \\*
    \( \leadsto \) trade-off between interactivity and overhead?
  \item \textbf{Goals}:
  \begin{itemize}
    \item higher priority for I/O jobs (usually don't use up quantum)
    \item low priority for CPU jobs (rather run them longer)
  \end{itemize}
  \item \textbf{Idea}: different queues with different priorities and time slice lengths
  \begin{itemize}
    \item schedule queues with (static) priority scheduling
    \item double time slice length in each next-lower priority
    \item process to higher priority when they don't use up quantum repetitively
    \item process to lower priority when they use up quantum repetitively
  \end{itemize}
\end{itemize}

\paragraph{Scheduling Principles --- priority donation}
\begin{itemize}
  \item \textbf{Problem}: Process B (higher priority) waits for process A (lower priority) \\*
    \( \leadsto \) B has now effectively lower priority
  \item \textbf{Solution}: \emph{priority donation}
  \begin{itemize}
    \item give A priority of B as long as B waits for A
    \item if C, D, E wait for B \( \to \) A gets highest priority of B, C, D, E
  \end{itemize}
\end{itemize}

\paragraph{Scheduling Policies --- lottery scheduling}
\begin{itemize}
  \item issue number of lottery tickets to processes (amount depending on priority)
  \item amount of tickets controls average proportion of CPU for each process
  \item \textbf{Scheduling}: scheduler draws random number \( N \), process with \( N \)-th ticket is executed
  \item processes can transfer tickets to other processes if they wait for them
\end{itemize}

\begin{summary}
  \begin{itemize}
    \item \textbf{phases}: processes have phases of communication and waiting for I/O
    \begin{itemize}
      \item[$ \to $] appropriate switching between processes increases computing system utilization
    \end{itemize}
    \item \textbf{goal-based}: scheduler decides what appropriate means based on goals
    \begin{itemize}
      \item \emph{long-term scheduler}: degree of multiprogramming
      \item \emph{short-term scheduler}: which process to run next
    \end{itemize}
    \item \textbf{dispatching}: only happens when OS is invoked
    \begin{itemize}
      \item \emph{cooperative scheduling}: currently running thread yields (syscall)
      \item \emph{preemptive scheduling}: OS is called periodically to switch threads
    \end{itemize}
  \end{itemize}
\end{summary}