\section{Page Faults}

\paragraph{Page Faults --- handling}
\begin{items}
  \item \textbf{Cause}: access to page currently not present in main memory \\*
    $ \to $ exception, invoking OS
  \item \textbf{Process}: \\*
    $ - $ OS checks access validity (requiring additional info) \\*
    $ - $ get empty frame \\*
    $ - $ load contents of requested page from disk into frame \\*
    $ - $ adapt page table \\*
    $ - $ set present bit of respective entry \\*
    $ - $ restart instruction causing page fault
\end{items}

\paragraph{Page Faults --- latency}
\begin{items}
  \item \textbf{fault rate} $ 0 \leq p \leq 1 $ \\*
    $ - $ $ p = 0 $: no page faults \\*
    $ - $ $ p = 1 $: every reference leads to page fault
  \item \textbf{effective access time} (EAT): \\*
    $ \text{EAT} = (1-p)*\text{memory access} + p*(\text{PF overhead} + \text{PF service time} + \text{restart overhead}) $
\end{items}

\paragraph{Page Faults --- performance impact}
\begin{items}
  \item \textbf{memory access time}: 200ns
  \item \textbf{average page fault service time}: 8ms
  \item $ \leadsto $ 1:1000 access-page-fault-rate $ \to $ $ \text{EAT} = 8.2\mu s $ $ \Rightarrow $ \emph{slowdown by factor 40}!
\end{items}

\paragraph{Page Faults --- challenges}
\begin{items}
  \item \textbf{what to eject?} \\*
    $ - $ how to allocate frames among processes? \\*
    $ - $ which particular process's pages to keep in memory? \\*
    $ - $ see \emph{page frame allocation}
  \item \textbf{what to fetch?} \\*
    $ - $ what if block size $ \neq $ page size? \\*
    $ - $ just one page needed? prefetch more?
  \item \textbf{process resumption?} \\*
    $ - $ need to save state + resume \\*
    $ - $ process might have been in middle of instruction
\end{items}

\paragraph{Page Faults --- what to fetch?}
\begin{items}
  \item bring in page causing fault
  \item \textbf{pre-fetch} sourrounding pages? \\*
    $ - $ reading two disk blocks is approximately as fast as reading one \\*
    $ - $ as long as there is no track/head switch, seek (disk) time dominates \\*
    $ - $ application exhibits spatial locality = big win
  \item \textbf{pre-zero} pages? \\*
    $ - $ don't want to leak information between processes \\*
    $ - $ need 0-filled pages for stack, heap, .bss, \dots \\*
    $ - $ \emph{zero on demand}? \\*
    $ - $ keep pool of 0-pages filled in background when CPU is idle?
\end{items}

\paragraph{Page Faults --- process resumption?}
\begin{items}
  \item hardware provides info about page fault \\*
    (intel: \code{\%cr2} contains faulting virtual address)
  \item \textbf{context}: OS needs to figure out fault context: \\*
    $ - $ read or write? \\*
    $ - $ instruction fetch? \\*
    $ - $ user access to kernel memory?
  \item \textbf{idempotent instructions}: easy: \\*
    $ - $ re-do load/store instructions \\*
    $ - $ re-execute instructions accessing only one address
  \item \textbf{complex instructions}: must be re-started \\*
    $ - $ some CISC instructions are hard to restart (e.g., block move of overlapping areas) \\*
    $ - $ \emph{solutions}: \\*
      \phantom{$ - $} $ \cdot $ touch relevant pages before operation starts \\*
      \phantom{$ - $} $ \cdot $ keep modified data in registers $ \to $ page faults can't take place \\*
      \phantom{$ - $} $ \cdot $ design ISA such that complex operations can execute partially $ \to $ consistent page fault state
\end{items}

\paragraph{Memory-Mapped Files --- other issues}
\begin{items}
  \item \textbf{I/O mapping}: mapping disk block to page in memory allows file I/O to be treated as routing memory  \\*
    $ - $ \emph{initial}: read page-sized portion of file from file system to physical page \\*
    $ - $ \emph{subsequent read/write}: treated as ordinary memory access \\*
    $ \to $ \emph{simplifies} file access, file I/O through memory instead of syscalls \\*
    $ \to $ \emph{memory-file sharing}: several processes can map to same file
\end{items}

\paragraph{Shared Data Segments}
\begin{items}
  \item \textbf{implementation}: \\*
    $ - $ temporary, asynchronous memory-mapped files \\*
    $ - $ shared pages (with allocated space on backing store)
  \item \textbf{copy on write} (COW): \\*
    $ - $ allows both parent and child process to initially share same memory pages \\*
    $ - $ only modified pages are copied $ \to $ more efficient process creation
\end{items}

\paragraph{Page Frame Allocation --- local vs. global}
\begin{items}
  \item \textbf{global}: all frames considered for replacement \\*
    $ - $ does not consider page ownership \\*
    $ - $ one process cannot get another process's frame \\*
    $ - $ does not protect process from a process that hogs all memory
  \item \textbf{local}: only frames of faulting process are considered for replacement \\*
    $ - $ isolates processes/users \\*
    $ - $ separately determine how many frames each process gets
\end{items}

\paragraph{Fixed Allocation --- equal vs. proportional}
\begin{items}
  \item \textbf{equal}: all processes get same amount of frames
  \item \textbf{proportional}: allocate according to process size \\*
    $ s_i \coloneqq \text{size of process } p_i $, $ S \coloneqq \sum s_i $, $ m \coloneqq \text{total number of frames } $ \\*
    $ \Rightarrow a_i \coloneqq \frac{s_i}{S}m $ allocation for $ p_i $
\end{items}

\paragraph{Fixed Allocation --- priority allocation}
\begin{items}
  \item = proportional allocation scheme using priorities rather than size
  \item \textbf{on page fault} of $ P_i $: \\*
    $ - $ select one of its frames for replacement or \\*
    $ - $ select frame from process with lower priority
\end{items}

\paragraph{Memory Locality}
\begin{items}
  \item \textbf{problem}: background storage much slower than memory \\*
    $ - $ paging extends memory size using background storage \\*
    $ - $ \emph{goal}: run near memory speed, not near background storage speed
  \item \textbf{Pareto principle}: applies to working sets of processes \\*
    $ - $ 10\% of memory gets 90\% of references \\*
    $ - $ \emph{goal}: keep those 10\% in memory, rest on disk \\*
    $ - $ \emph{problem}: how to identify those 10\%?
\end{items}

\paragraph{Thrashing}
\begin{items}
  \item \textbf{problem}: system is busy swapping pages in and out \\*
    $ - $ each time one page is brought in, another page, whose contents will soon matter, is thrown out \\*
    $ - $ \emph{effect}: low CPU utilization, processes wait for pages to be fetched from disk \\*
    $ - $ \emph{consequence}: OS thinks that it needs higher degree of multiprogramming
  \item \textbf{reasons}: \\*
    $ - $ \emph{no temporal locality} of access pattern --- process doesn't follow Pareto principle \\*
    $ - $ \emph{too much multiprogramming}: each process fits individually, but too many for system \\*
    $ - $ \emph{memory too small} to hold hot memory of a single process (the 10\%) \\*
    $ - $ \emph{bad page replacement policy}
\end{items}

\paragraph{Working-Set Model}
\begin{items}
  \item $ \Delta \coloneqq $ working-set window (fixed number of page references; e.g., 10000 instructions)
  \item $ \text{WSS}_i \coloneqq $ working set of process $ P_i $ \\*
    $ - $ total number of pages referenced in most recent $ \Delta $ (varies in time) \\*
    $ - $ $ \Delta \begin{cases}
      \text{too small} &\Rightarrow \text{ will not encompass entire locality} \\
      \text{too large} &\Rightarrow \text{ will encompass several localities} \\
      = \infty &\Rightarrow \text{ will encompass entire program}
    \end{cases} $
  \item $ D \coloneqq \sum \text{WSS}_i = $ total demand for frames \\*
    $ - $ $ D > m \leadsto $ \textbf{thrashing} \\*
    $ \to $ $ D > m \Rightarrow $ suspend a process
\end{items}

\paragraph{Working Set --- keeping track}
\begin{items}
  \item \textbf{perfect}: replace page that is referenced furthest in the future (\emph{oracle})
  \item \textbf{idea}: predict future from past \\*
    $ - $ record page references from past and extrapolate into future \\*
    $ - $ \emph{problem}: too expensive to make ordered list of all page references at runtime
  \item \textbf{idea}: sacrifice precision for speed \\*
    $ - $ MMU sets \emph{reference bit} in respective page table entry every time a page is referenced \\*
    $ - $ set timer to scan all page table entries for reference bits
\end{items}

\paragraph{Page Fault Frequency --- allocation scheme}
\begin{items}
  \item \textbf{goal}: establish acceptable page fault rate \\*
    $ - $ \emph{actual rate too low} $ \to $ give frames to other process \\*
    $ - $ \emph{actual rate too high} $ \to $ allocate more frames to process
\end{items}

\paragraph{Page Fetch Policy --- demand paging}
\begin{items}
  \item \textbf{idea}: only transfer pages raising page faults
  \item \textbf{advantages}: \\*
    $ - $ only transfer what is needed \\*
    $ - $ less memory needed by process $ \to $ higher multiprogramming degree possible
  \item \textbf{disadvantages}: \\*
    $ - $ many initial page faults when task starts \\*
    $ - $ more I/O operations $ \to $ more I/O overhead
\end{items}

\paragraph{Page Fetch Policy --- pre-paging}
\begin{items}
  \item \textbf{idea}: speculatively transfer pages to RAM \\*
    $ - $ at every page fault: speculate what else should be loaded \\*
    $ - $ e.g., load entire text section when process starts
  \item \textbf{advantage}: improves disk I/O throughput
  \item \textbf{disadvantages}: \\*
    $ - $ wastes I/O bandwidth if page is never used \\*
    $ - $ can destroy working set of other processes in case of page stealing
\end{items}

\begin{summary}
  \begin{items}
    \item paging simulates a memory size of the size of the virtual memory
    \item when pages are filled via page faults, OS needs to answer some questions: \\*
      $ - $ what to eject? \\*
      $ - $ what to fetch? \\*
      $ - $ how to resume process?
    \item different strategies to allocate frames and replace pages: \\*
      $ - $ local vs. global allocation \\*
      $ - $ fixed vs. proportional vs. priority allocation
    \item \emph{thrashing} must be prevented by taking working sets of active processes into account
  \end{items}
\end{summary}